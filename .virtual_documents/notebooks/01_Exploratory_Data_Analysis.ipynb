# %% CELL 1 ── Reproducibility & Data Load ──
import os, random, json, numpy as np, pandas as pd, matplotlib.pyplot as plt, seaborn as sns
from pathlib import Path
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report, confusion_matrix
import numpy as np

# 1. Define Features (X) and Target (y)
# (Using the same features as Logistic Regression: run_hours, temp_avg, pressure_avg, vibration)
X = data.drop(['failure_flag', 'sensor_id'], axis=1) 
y = data['failure_flag']

# 2. Perform a Stratified Train/Test Split 
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print(f"Train set size: {X_train.shape[0]} samples")
print(f"Test set size: {X_test.shape[0]} samples")


# 1. Train the Decision Tree Model
dt_model = DecisionTreeClassifier(random_state=42, class_weight="balanced")
dt_model.fit(X_train, y_train)

# 2. Make Predictions
dt_prediction = dt_model.predict(X_test)

# 3. Output Evaluation Metrics
print("--- Decision Tree Model Evaluation ---")
print("\nClassification Report:\n", classification_report(y_test, dt_prediction, zero_division=0))
print("\nTest Accuracy:", accuracy_score(y_test, dt_prediction))

# 4. Generate Confusion Matrix 
dt_cm = confusion_matrix(y_test, dt_prediction)
print("\nConfusion Matrix:\n", dt_cm)

SEED = 42
random.seed(SEED); np.random.seed(SEED); os.environ['PYTHONHASHSEED'] = str(SEED)
sns.set_style("whitegrid")

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import os

# --- 1. Define Features (X) and Target (y) ---
X = data.drop(['failure_flag', 'sensor_id'], axis=1) 
y = data['failure_flag']
rule_pred = np.where((data['run_hours'] >= 1500) & (data['vibration'] > 2.0), 1, 0)

def scores(pred, true=y):
    return {'Acc': accuracy_score(true, pred),
            'Prec': precision_score(true, pred, zero_division=0),
            'Rec': recall_score(true, pred, zero_division=0),
            'F1': f1_score(true, pred, zero_division=0)}
# 2. Stratified Train/Test Split
# Note: stratify=y is CRITICAL for balancing the small test set.
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print("--- Data Split Confirmation ---")
print(f"Train set size: {X_train.shape[0]} samples (Failures: {y_train.sum()})")
print(f"Test set size: {X_test.shape[0]} samples (Failures: {y_test.sum()})\n")


# --- 3. Heuristic Baseline on Holdout (X_test) ---
rule_prediction = np.where((X_test['run_hours'] >= 1500) & (X_test['vibration'] > 2.0), 1, 0)
cm_rule = confusion_matrix(y_test, rule_prediction)

rule_accuracy = accuracy_score(y_test, rule_prediction)
rule_precision = precision_score(y_test, rule_prediction, zero_division=0)
rule_recall = recall_score(y_test, rule_prediction, zero_division=0)
rule_f1 = f1_score(y_test, rule_prediction, zero_division=0)


# --- 4. Plot and Save Confusion Matrix (Heuristic) ---
os.makedirs("figures", exist_ok=True)
labels = ["No Failure", "Failure"]

rule_scores = scores(rule_pred)
print("Heuristic (full):", rule_scores)

# %% CELL 5 ── Train/Test Split & Hold-out Test ──
X = data.drop(['failure_flag', 'sensor_id'], axis=1)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=SEED, stratify=y)

print(f"Train: {X_train.shape[0]}  Test: {X_test.shape[0]}  Failures in test: {y_test.sum()}")

# %% CELL 6 ── Models ──
models = {
    'Heuristic': lambda x: np.where((x['run_hours'] >= 1500) & (x['vibration'] > 2.0), 1, 0),
    'LogReg': LogisticRegression(solver='liblinear', random_state=SEED),
    'DecTree': DecisionTreeClassifier(random_state=SEED, class_weight='balanced')
}

results = {}
for name, mdl in models.items():
    if callable(mdl):          # heuristic
        pred = mdl(X_test)
    else:                      # sklearn
        mdl.fit(X_train, y_train)
        pred = mdl.predict(X_test)
    results[name] = scores(pred, y_test)

# Convert to DataFrame 
metrics_df = pd.DataFrame(results).T.round(2)
print("\nHold-out metrics:")
print(metrics_df)

# %% CELL 7 ── Confusion Matrix Plot ──
os.makedirs("figures", exist_ok=True)
labels = ["No Failure", "Failure"]

def plot_cm(preds, name):
    cm = confusion_matrix(y_test, preds)
    plt.figure(figsize=(3.5, 3))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=labels, yticklabels=labels, linewidths=.5)
    plt.title(f"{name} — Hold-out CM"); plt.tight_layout()
    plt.savefig(f"figures/cm_{name.lower().replace(' ', '')}.png", dpi=150); plt.show()

for n, mdl in models.items():
    pred = mdl(X_test) if callable(mdl) else mdl.predict(X_test)
    plot_cm(pred, n)

# %% CELL 8 ── Export Production Artefacts ──
from joblib import dump
final_model = LogisticRegression(solver='liblinear', random_state=SEED)
final_model.fit(X, y)               # re-train on FULL data
dump(final_model, DATA_DIR / "logreg_model.joblib")
dump(X.columns.to_list(), DATA_DIR / "feature_names.joblib")
print("✔ Model & feature list saved → /data/")




